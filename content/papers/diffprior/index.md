---
title: "Learning Diffusion Priors from Observations by Expectation Maximization" 
date: 2025-10-29
url: /papers/diffusion_prior
tags: ["keyword 1","keyword 2"]
author: ["Andry Gérôme"]
description: "TODO" 
summary: "TODO"
cover:
    image: "banner.png"
    alt: "Figure from paper"
    relative: false
editPost:
    URL: "https://doi.org/paper_doi"
    Text: "Journal/Repository Name"
showToc: true

---
<p style="text-align: center;">THIS PAGE IS STILL WIP</p>

---

<!-- ##### Download:

- [Paper](/paper.pdf)
- [Online appendix](/appendix.pdf)
- [Code and data](https://github.com/paper_repo)

--- -->

##### Abstract:

Diffusion models recently proved to be remarkable priors for Bayesian inverse problems. However, training these models typically requires access to large amounts of clean data, which could prove difficult in some settings. In this work, we present a novel method based on the expectation-maximization algorithm for training diffusion models from incomplete and noisy observations only. Unlike previous works, our method leads to proper diffusion models, which is crucial for downstream tasks. As part of our method, we propose and motivate an improved posterior sampling scheme for unconditional diffusion models. We present empirical evidence supporting the effectiveness of our method

<!-- ---

##### Figure X:  Figure title

![](/figurex.png)

---

##### Citation

Author 1, Author 2. Year. "Title." *Journal* Volume (Issue): First page–Last page. https://doi.org/paper_doi.

```BibTeX
@article{AAYY,
author = {Author 1 and Author 2},
doi = {paper_doi},
journal = {Journal},
number = {Issue},
pages = {XXX--YYY},
title = {Title},
volume = {Volume},
year = {Year}}
```

---

##### Related material

+ [Presentation slides](/presentation.pdf) -->